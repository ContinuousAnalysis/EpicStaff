from datetime import datetime, timezone
from collections import defaultdict
import uuid
import base64
from tables.models.graph_models import TelegramTriggerNode
from tables.services.telegram_trigger_service import TelegramTriggerService
from tables.serializers.telegram_trigger_serializers import (
    TelegramTriggerNodeDataFieldsSerializer,
)
from tables.utils.telegram_fields import load_telegram_trigger_fields
from tables.models import Tool
from tables.models import Crew
from tables.models import GraphFile
from tables.models.crew_models import DefaultAgentConfig, DefaultCrewConfig
from tables.models.embedding_models import DefaultEmbeddingConfig
from tables.models.llm_models import DefaultLLMConfig
from tables.services.realtime_service import RealtimeService
from utils.logger import logger

from drf_yasg import openapi
from drf_yasg.utils import swagger_auto_schema
from django.db import transaction
from django.db.models import Count, Q, Prefetch
from django.conf import settings

from django.utils.decorators import method_decorator
from django.views.decorators.cache import cache_page

from rest_framework.mixins import RetrieveModelMixin, UpdateModelMixin, ListModelMixin
from rest_framework.viewsets import GenericViewSet

from rest_framework.decorators import api_view, action
from rest_framework.views import APIView
from rest_framework.generics import ListAPIView
from rest_framework import generics
from rest_framework import viewsets, mixins
from rest_framework.response import Response
from rest_framework import status
from rest_framework.exceptions import NotFound, ValidationError
from rest_framework import filters

from tables.services.config_service import YamlConfigService
from tables.services.session_manager_service import SessionManagerService
from tables.services.converter_service import ConverterService
from tables.services.redis_service import RedisService
from tables.services.run_python_code_service import RunPythonCodeService
from tables.services.quickstart_service import QuickstartService
from tables.services.knowledge_services.indexing_service import IndexingService

from django_filters.rest_framework import DjangoFilterBackend


from tables.models import (
    Session,
    SourceCollection,
    # DocumentMetadata,
    GraphOrganization,
    GraphOrganizationUser,
    OrganizationUser,
    Graph,
)
from tables.serializers.model_serializers import (
    SessionSerializer,
    SessionLightSerializer,
    DefaultLLMConfigSerializer,
    DefaultEmbeddingConfigSerializer,
    ToolSerializer,
)
from tables.serializers.serializers import (
    AnswerToLLMSerializer,
    EnvironmentConfigSerializer,
    InitRealtimeSerializer,
    ProcessCollectionEmbeddingSerializer,
    ProcessRagIndexingSerializer,
    RunSessionSerializer,
    RegisterTelegramTriggerSerializer,
)

# from tables.serializers.knowledge_serializers import CollectionStatusSerializer
from tables.serializers.quickstart_serializers import QuickstartSerializer
from tables.filters import SessionFilter  # CollectionFilter,

from .default_config import *


MAX_TOTAL_FILE_SIZE = 15 * 1024 * 1024  # 15MB

redis_service = RedisService()
# TODO: fix. Do we need init converter_service here? Instance is not used.
converter_service = ConverterService()
session_manager_service = SessionManagerService()
config_service = YamlConfigService()
run_python_code_service = RunPythonCodeService()
realtime_service = RealtimeService()
quickstart_service = QuickstartService()


class SessionViewSet(
    mixins.ListModelMixin,
    mixins.RetrieveModelMixin,
    mixins.DestroyModelMixin,
    viewsets.GenericViewSet,
):
    """
    API endpoints for managing session objects.

    Supports listing, retrieving, deleting sessions,
    bulk deletion, and reporting aggregated status counts.
    """

    serializer_class = SessionSerializer
    filter_backends = [DjangoFilterBackend, filters.OrderingFilter]
    filterset_class = SessionFilter
    ordering_fields = [
        "created_at",
        "finished_at",
        "status",
        "status_updated_at",
        "id",
    ]  # allowed fields
    ordering = ["-created_at", "id"]  # default ordering

    @swagger_auto_schema(
        operation_description="Retrieve a list of sessions.",
        manual_parameters=[
            openapi.Parameter(
                name="detailed",
                in_=openapi.IN_QUERY,
                description="Whether to include all session details. Set to `false` to return only minimal fields. The `true` value is deprecated and will be removed in a future version.",
                required=False,
                type=openapi.TYPE_BOOLEAN,
                default=True,
            )
        ],
    )
    def list(self, request, *args, **kwargs):
        return super().list(request, *args, **kwargs)

    def get_serializer_class(self):
        detailed = self.request.query_params.get("detailed", "true").lower()
        if detailed == "false":
            return SessionLightSerializer
        return SessionSerializer

    def get_queryset(self):
        return Session.objects.select_related("graph")

    @swagger_auto_schema(
        operation_description="Get counts of each status grouped by graph ID",
        responses={
            200: openapi.Schema(
                type=openapi.TYPE_OBJECT,
                properties={
                    "graph_id": openapi.Schema(
                        type=openapi.TYPE_OBJECT,
                        properties={
                            choice.value: openapi.Schema(
                                type=openapi.TYPE_INTEGER, description=choice.label
                            )
                            for choice in Session.SessionStatus
                        },
                        description="Status counts",
                    ),
                },
                description="Mapping of graph_id to status counts",
            )
        },
    )
    @action(detail=False, methods=["GET"])
    def statuses(self, request):
        queryset = self.get_queryset()

        # Apply filters
        for backend in list(self.filter_backends):
            queryset = backend().filter_queryset(request, queryset, self)

        queryset = queryset.values("graph_id", "status").annotate(count=Count("status"))
        data = defaultdict(lambda: defaultdict(int))
        for row in queryset:
            data[row["graph_id"]][row["status"]] = row["count"]

        return Response(data)

    @swagger_auto_schema(
        method="post",
        operation_description="Delete multiple sessions by IDs",
        request_body=openapi.Schema(
            type=openapi.TYPE_OBJECT,
            required=["ids"],
            properties={
                "ids": openapi.Schema(
                    type=openapi.TYPE_ARRAY,
                    items=openapi.Items(type=openapi.TYPE_INTEGER),
                    description="List of session IDs to delete",
                )
            },
        ),
        responses={200: openapi.Response("Successfully deleted IDs")},
    )
    @action(detail=False, methods=["post"], url_path="bulk_delete")
    def bulk_delete(self, request):
        ids = request.data.get("ids", [])
        if not isinstance(ids, list) or not all(isinstance(i, int) for i in ids):
            return Response(
                {"detail": "ids must be a list of integers."},
                status=status.HTTP_400_BAD_REQUEST,
            )

        with transaction.atomic():
            session_list = Session.objects.filter(id__in=ids)
            deleted_count = session_list.count()
            for session in session_list:
                session.delete()

        return Response(
            {"deleted": deleted_count, "ids": ids}, status=status.HTTP_200_OK
        )


class RunSession(APIView):

    @swagger_auto_schema(
        request_body=RunSessionSerializer,
        responses={
            201: openapi.Response(
                description="Session Started",
                examples={"application/json": {"session_id": 123}},
            ),
            400: "Bad Request - Invalid Input",
        },
    )
    def post(self, request):
        logger.info("Received POST request to start a new session.")

        total_size = sum(f.size for f in request.FILES.values())
        max_mb = round(settings.MAX_TOTAL_FILE_SIZE / 1024 / 1024, 2)
        got_mb = round(total_size / 1024 / 1024, 2)

        if got_mb > max_mb:
            return Response(
                {
                    "files": [
                        f"Total files size exceeds {max_mb:.2f} MB (got {got_mb:.2f} MB)"
                    ]
                },
                status=400,
            )

        serializer = RunSessionSerializer(data=request.data)
        if not serializer.is_valid():
            logger.warning(f"Invalid data received in request: {serializer.errors}")
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        files_dict = {}
        graph_id = serializer.validated_data["graph_id"]
        username = serializer.validated_data.get("username")
        graph_organization_user = None

        graph = Graph.objects.filter(id=graph_id).first()
        if not graph:
            return Response(
                {"message": f"Provided graph does not exist"},
                status=status.HTTP_404_NOT_FOUND,
            )

        graph_organization = GraphOrganization.objects.filter(
            graph__id=graph_id
        ).first()

        if username and not graph_organization:
            return Response(
                {"message": "No GraphOrganization exists for this flow."},
                status=status.HTTP_400_BAD_REQUEST,
            )

        if username and graph_organization:
            user = OrganizationUser.objects.filter(
                name=username, organization=graph_organization.organization
            ).first()
            if not user and username:
                return Response(
                    {
                        "message": f"Provided user does not exist or does not belong to organization {graph_organization.organization.name}"
                    },
                    status=status.HTTP_404_NOT_FOUND,
                )

            graph_organization_user, _ = GraphOrganizationUser.objects.get_or_create(
                user=user,
                graph=graph,
                defaults={"persistent_variables": graph_organization.user_variables},
            )

        variables = serializer.validated_data.get("variables", {})
        graph_files = GraphFile.objects.filter(graph__id=graph_id)

        for graph_file in graph_files:
            files_dict[graph_file.domain_key] = self._get_file_data(
                graph_file.file, graph_file.content_type
            )

        for key, file in request.FILES.items():
            files_dict[key] = self._get_file_data(file, file.content_type)

        if files_dict is not None:
            variables["files"] = files_dict
            logger.info(f"Added {len(files_dict)} files to variables.")
        if graph_organization:
            variables.update(graph_organization.persistent_variables)
            logger.info(
                f"Organization variables are used for this flow. Variables: {graph_organization.persistent_variables}"
            )
        if graph_organization_user:
            variables.update(graph_organization_user.persistent_variables)
            logger.info(
                f"Organization user variables are used for this flow. Variables: {graph_organization_user.persistent_variables}"
            )

        try:
            # Publish session to: crew, maanger
            session_id = session_manager_service.run_session(
                graph_id=graph_id, variables=variables, username=username
            )
            logger.info(f"Session {session_id} successfully started.")
        except Exception as e:
            logger.exception(
                f"Error occurred while starting session for graph_id {graph_id}"
            )
            return Response(status=status.HTTP_400_BAD_REQUEST, data={"error": str(e)})
        else:
            return Response(
                data={"session_id": session_id}, status=status.HTTP_201_CREATED
            )

    def _get_file_data(self, file, content_type):
        file_bytes = file.read()

        return {
            "name": file.name,
            "base64_data": base64.b64encode(file_bytes).decode("utf-8"),
            "content_type": content_type,
        }


class GetUpdates(APIView):
    @swagger_auto_schema(
        responses={
            200: openapi.Response(
                description="Session details retrieved successfully",
                examples={
                    "application/json": {
                        "status": "run",
                        "conversation": "Sample conversation",
                    }
                },
            ),
            404: openapi.Response(
                description="Session not found or session ID missing"
            ),
        }
    )
    def get(self, request, *args, **kwargs):

        session_id = kwargs.get("session_id", None)
        if session_id is None:
            return Response("Session id not found", status=status.HTTP_404_NOT_FOUND)

        try:
            session_status = session_manager_service.get_session_status(
                session_id=session_id
            )
        except Session.DoesNotExist:
            return Response("Session not found", status=status.HTTP_404_NOT_FOUND)

        return Response(
            data={"status": session_status},
            status=status.HTTP_200_OK,
        )


class StopSession(APIView):

    @swagger_auto_schema(
        responses={
            204: openapi.Response(description="Session stoped"),
            404: openapi.Response(
                description="Session not found or session ID missing"
            ),
        },
    )
    def post(self, request, *args, **kwargs):
        session_id = kwargs.get("session_id", None)
        if session_id is None:
            return Response("Session id is missing", status=status.HTTP_404_NOT_FOUND)
        try:
            required_listeners = 2  # manager and crew
            received_n = session_manager_service.stop_session(session_id=session_id)
            if received_n < required_listeners:

                logger.error(f"Stop session ({session_id}) was sent but not received.")
                session = Session.objects.get(pk=session_id)
                session.status = Session.SessionStatus.ERROR
                session.status_data = {
                    "reason": f"Data was sent and received by ({received_n}) listeners, but ({required_listeners}) required."
                }
                session.save()

        except Session.DoesNotExist:
            return Response("Session not found", status=status.HTTP_404_NOT_FOUND)

        return Response(status=status.HTTP_204_NO_CONTENT)


class EnvironmentConfig(APIView):
    @swagger_auto_schema(
        responses={
            200: openapi.Response(
                description="Config retrieved successfully",
                examples={"application/json": {"data": {"key": "value"}}},
            ),
        },
    )
    def get(self, request, format=None):

        config_dict: dict = config_service.get_all()
        logger.info("Configuration retrieved successfully.")

        return Response(status=status.HTTP_200_OK, data={"data": config_dict})

    @swagger_auto_schema(
        request_body=EnvironmentConfigSerializer,
        responses={
            201: openapi.Response(
                description="Config updated successfully",
                examples={"application/json": {"data": {"key": "value"}}},
            ),
            400: openapi.Response(description="Invalid config data provided"),
        },
    )
    def post(self, request, *args, **kwargs):

        serializer = EnvironmentConfigSerializer(data=request.data)
        if not serializer.is_valid():
            logger.error("Invalid configuration data provided.")
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        config_service.set_all(config_dict=serializer.validated_data["data"])
        logger.info("Configuration updated successfully.")

        updated_config = config_service.get_all()

        return Response(data={"data": updated_config}, status=status.HTTP_201_CREATED)


@swagger_auto_schema(
    method="delete",
    responses={
        204: openapi.Response(description="Config deleted successfully"),
        400: openapi.Response(description="No key provided"),
        404: openapi.Response(description="Key not found"),
    },
)
@api_view(["DELETE"])
def delete_environment_config(request, *args, **kwargs):
    key: str | None = kwargs.get("key", None)

    if key is None:
        logger.error("No key provided in DELETE request.")
        return Response("No key provided", status=status.HTTP_400_BAD_REQUEST)

    deleted_key = config_service.delete(key=key)

    if not deleted_key:
        logger.warning(f"Key '{key}' not found.")
        return Response("Key not found", status=status.HTTP_404_NOT_FOUND)

    logger.info(f"Config key '{key}' deleted successfully.")
    return Response("Config deleted successfully", status=status.HTTP_204_NO_CONTENT)


class AnswerToLLM(APIView):

    @swagger_auto_schema(
        request_body=AnswerToLLMSerializer,
        responses={
            202: openapi.Response(description="User input sent"),
            400: openapi.Response(description="Invalid data provided"),
            404: openapi.Response(description="Session not found"),
            418: openapi.Response(description="Session status is not wait_for_input"),
        },
    )
    def post(self, request, *args, **kwargs):
        serializer = AnswerToLLMSerializer(data=request.data)
        if not serializer.is_valid():
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        session_id = serializer.validated_data["session_id"]
        name = serializer.validated_data["name"]
        crew_id = serializer.validated_data["crew_id"]
        execution_order = serializer.validated_data["execution_order"]
        answer = serializer.validated_data["answer"]
        try:
            session = Session.objects.get(id=session_id)
        except Session.DoesNotExist:
            return Response("Session not found", status=status.HTTP_404_NOT_FOUND)

        logger.info(
            f"{session.status} == {Session.SessionStatus.WAIT_FOR_USER} : {session.status == Session.SessionStatus.WAIT_FOR_USER}"
        )

        if session.status != Session.SessionStatus.WAIT_FOR_USER:
            return Response(
                "Session status is not wait_for_user",
                status=status.HTTP_418_IM_A_TEAPOT,
            )

        created_at_dt = datetime.now(timezone.utc)
        created_at_iso = created_at_dt.isoformat(timespec="milliseconds").replace(
            "+00:00", "Z"
        )

        session_manager_service.register_message(
            data={
                "session_id": session_id,
                "name": name,
                "execution_order": execution_order,
                "timestamp": created_at_iso,
                "message_data": {
                    "text": answer,
                    "crew_id": crew_id,
                    "message_type": "user",
                },
                "uuid": str(uuid.uuid4()),
            },
            created_at_dt=created_at_dt,
        )

        redis_service.send_user_input(
            session_id=session_id,
            node_name=name,
            crew_id=crew_id,
            execution_order=execution_order,
            message=answer,
        )

        return Response(status=status.HTTP_202_ACCEPTED)


class CrewDeleteAPIView(APIView):

    @swagger_auto_schema(
        manual_parameters=[
            openapi.Parameter(
                name="delete_sessions",
                in_=openapi.IN_QUERY,
                type=openapi.TYPE_STRING,
                description="Delete all sessions associated (true/false). Default is false.",
                required=False,
            )
        ],
        responses={
            200: "Crew deleted successfully",
            400: "Invalid value for delete_sessions",
            404: "Crew not found",
        },
    )
    def delete(self, request, id):

        delete_sessions = request.query_params.get("delete_sessions", "false").lower()
        if delete_sessions not in {"true", "false"}:
            raise ValidationError(
                {"error": "Invalid value for delete_sessions. Use 'true' or 'false'."}
            )

        delete_sessions = delete_sessions == "true"

        crew = Crew.objects.filter(id=id).first()
        if not crew:
            raise NotFound({"error": "Crew not found"})

        try:
            with transaction.atomic():
                if delete_sessions:
                    Session.objects.filter(crew=crew).delete()
                else:
                    Session.objects.filter(crew=crew).update(crew=None)

                crew.delete()

            return Response(
                {"message": "Crew deleted successfully"}, status=status.HTTP_200_OK
            )
        except Exception as e:
            return Response(
                {"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )


class DefaultLLMConfigAPIView(APIView):

    @swagger_auto_schema(
        operation_summary="Get llm config defaults",
        responses={
            200: DefaultLLMConfigSerializer,
            404: openapi.Response(description="Object not found"),
        },
    )
    def get(self, request, *args, **kwargs):
        obj = DefaultLLMConfig.objects.first()
        serializer = DefaultLLMConfigSerializer(obj, many=False)

        return Response(serializer.data)

    @swagger_auto_schema(
        operation_summary="Update llm config defaults",
        request_body=DefaultLLMConfigSerializer,
        responses={
            200: DefaultLLMConfigSerializer,
            404: openapi.Response(description="Object not found"),
            400: openapi.Response(description="Validation Error"),
        },
    )
    def put(self, request, *args, **kwargs):

        try:
            obj = DefaultLLMConfig.objects.get(pk=1)
        except DefaultLLMConfig.DoesNotExist:
            return Response(
                {"error": "Object not found"}, status=status.HTTP_404_NOT_FOUND
            )

        serializer = DefaultLLMConfigSerializer(obj, data=request.data)
        if serializer.is_valid():
            serializer.save()
            return Response(serializer.data)
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


class DefaultEmbeddingConfigAPIView(APIView):

    @swagger_auto_schema(
        operation_summary="Get embedding config defaults",
        responses={
            200: DefaultEmbeddingConfigSerializer,
            404: openapi.Response(description="Object not found"),
        },
    )
    def get(self, request, *args, **kwargs):
        obj = DefaultEmbeddingConfig.objects.first()
        serializer = DefaultEmbeddingConfigSerializer(obj, many=False)

        return Response(serializer.data)

    @swagger_auto_schema(
        operation_summary="Update embedding config defaults",
        request_body=DefaultEmbeddingConfigSerializer,
        responses={
            200: DefaultEmbeddingConfigSerializer,
            404: openapi.Response(description="Object not found"),
            400: openapi.Response(description="Validation Error"),
        },
    )
    def put(self, request, *args, **kwargs):

        try:
            obj = DefaultEmbeddingConfig.objects.get(pk=1)
        except DefaultEmbeddingConfig.DoesNotExist:
            return Response(
                {"error": "Object not found"}, status=status.HTTP_404_NOT_FOUND
            )

        serializer = DefaultEmbeddingConfigSerializer(obj, data=request.data)
        if serializer.is_valid():
            serializer.save()
            return Response(serializer.data)
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


class ToolListRetrieveUpdateGenericViewSet(
    ListModelMixin, RetrieveModelMixin, UpdateModelMixin, GenericViewSet
):
    queryset = Tool.objects.prefetch_related("tool_fields")
    serializer_class = ToolSerializer


class RunPythonCodeAPIView(APIView):
    @swagger_auto_schema(
        operation_summary="Run Python Code",
        request_body=openapi.Schema(
            type=openapi.TYPE_OBJECT,
            properties={
                "python_code_id": openapi.Schema(
                    type=openapi.TYPE_INTEGER,
                    description="ID of the Python code to execute",
                ),
                "variables": openapi.Schema(
                    type=openapi.TYPE_OBJECT,
                    additional_properties=openapi.Schema(type=openapi.TYPE_STRING),
                    description="Key-value arguments for the code",
                ),
            },
            required=["python_code_id"],
        ),
        responses={
            200: openapi.Response(
                description="Execution ID",
                schema=openapi.Schema(
                    type=openapi.TYPE_OBJECT,
                    properties={
                        "execution_id": openapi.Schema(
                            type=openapi.TYPE_INTEGER, description="ID of the execution"
                        )
                    },
                ),
            ),
            400: "Bad Request",
        },
    )
    def post(self, request):
        python_code_id = request.data.get("python_code_id")
        variables = request.data.get("variables", {})

        if not python_code_id:
            return Response(
                {"error": "python_code_id is required"},
                status=status.HTTP_400_BAD_REQUEST,
            )

        execution_id = run_python_code_service.run_code(python_code_id, variables)
        return Response({"execution_id": execution_id}, status=status.HTTP_200_OK)


class InitRealtimeAPIView(APIView):

    @swagger_auto_schema(
        request_body=InitRealtimeSerializer,
        responses={
            201: openapi.Response(
                description="Realtime agent created successfully",
                examples={
                    "application/json": {
                        "connection_key": "d8cb1ef6-28a3-4689-a0b6-4faeb05a4f2b"
                    }
                },
            ),
            400: "Bad Request - Invalid Input",
        },
    )
    def post(self, request):
        logger.info("Received POST request to start a new session.")

        serializer = InitRealtimeSerializer(data=request.data)
        if not serializer.is_valid():
            logger.warning(f"Invalid data received in request: {serializer.errors}")
            return Response(
                serializer.errors,
                status=status.HTTP_400_BAD_REQUEST,
                data={"error": str(serializer.errors)},
            )

        agent_id = serializer.validated_data["agent_id"]

        try:
            connection_key = realtime_service.init_realtime(
                agent_id=agent_id,
            )

        except Exception as e:
            logger.exception(
                f"Error occurred while creating realtime agent for agent_id {agent_id}"
            )
            return Response(status=status.HTTP_400_BAD_REQUEST, data={"error": str(e)})
        else:
            return Response(
                data={"connection_key": connection_key}, status=status.HTTP_201_CREATED
            )


class QuickstartView(APIView):
    """
    API endpoint for managing quickstart configurations
    """

    @swagger_auto_schema(
        operation_description="Get list of supported providers",
        responses={200: openapi.Response(description="List of supported providers")},
    )
    def get(self, request):
        """
        Get list of supported providers for quickstart configuration
        """
        try:
            supported_providers = list(quickstart_service.get_supported_providers())

            return Response(
                data={
                    "supported_providers": supported_providers,
                    "count": len(supported_providers),
                },
                status=status.HTTP_200_OK,
            )

        except Exception as e:
            logger.error(f"Error getting supported providers: {str(e)}")
            return Response(
                data={
                    "detail": "Failed to retrieve supported providers",
                    "error": "An unexpected error occurred",
                },
                status=status.HTTP_500_INTERNAL_SERVER_ERROR,
            )

    @swagger_auto_schema(
        request_body=QuickstartSerializer,
        responses={202: openapi.Response(description="Chunking operation accepted")},
    )
    def post(self, request):
        serializer = QuickstartSerializer(data=request.data)
        if serializer.is_valid():
            provider = serializer.validated_data["provider"]
            api_key = serializer.validated_data["api_key"]

            quickstart = quickstart_service.quickstart(provider, api_key)

            if quickstart.get("success", False):
                config_name = quickstart.get("config_name")
                return Response(
                    data={
                        "detail": "Quickstart initiated successfully!",
                        "config_name": config_name,
                    },
                    status=status.HTTP_200_OK,
                )
            else:
                error = quickstart.get("error")
                return Response(
                    data={"detail": "Error quickstart", "error": error},
                    status=status.HTTP_400_BAD_REQUEST,
                )
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


class ProcessRagIndexingView(APIView):
    """
    View for triggering RAG indexing (chunking + embedding).
    All business logic is handled by IndexingService.
    """

    @swagger_auto_schema(
        request_body=ProcessRagIndexingSerializer,
        responses={
            202: "Indexing process accepted and queued",
            400: "Invalid request or RAG not ready for indexing",
            404: "RAG configuration not found",
        },
    )
    def post(self, request):
        serializer = ProcessRagIndexingSerializer(data=request.data)
        if not serializer.is_valid():
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        rag_id = serializer.validated_data["rag_id"]
        rag_type = serializer.validated_data["rag_type"]

        try:
            indexing_data = IndexingService.validate_and_prepare_indexing(
                rag_id=rag_id, rag_type=rag_type
            )

            redis_service.publish_rag_indexing(
                rag_id=indexing_data["rag_id"],
                rag_type=indexing_data["rag_type"],
                collection_id=indexing_data["collection_id"],
            )

            return Response(
                data={
                    "detail": "Indexing process accepted",
                    "rag_id": indexing_data["rag_id"],
                    "rag_type": indexing_data["rag_type"],
                    "collection_id": indexing_data["collection_id"],
                },
                status=status.HTTP_202_ACCEPTED,
            )

        except Exception as e:
            # DRF handle
            raise


class ProcessCollectionEmbeddingView(APIView):
    @swagger_auto_schema(request_body=ProcessCollectionEmbeddingSerializer)
    def post(self, request):
        serializer = ProcessCollectionEmbeddingSerializer(data=request.data)
        if serializer.is_valid():
            collection_id = serializer["collection_id"].value
            if not SourceCollection.objects.filter(
                collection_id=collection_id
            ).exists():
                return Response(status=status.HTTP_404_NOT_FOUND)
            redis_service.publish_source_collection(collection_id=collection_id)
            return Response(status=status.HTTP_202_ACCEPTED)


class TelegramTriggerNodeAvailableFieldsView(APIView):
    """
    GET endpoint that returns all possible fields that can be created
    for TelegramTriggerNode.
    """

    def get(self, request, format=None):
        data = load_telegram_trigger_fields()
        serializer = TelegramTriggerNodeDataFieldsSerializer({"data": data})
        return Response(serializer.data, status=status.HTTP_200_OK)


class RegisterTelegramTriggerApiView(APIView):
    @swagger_auto_schema(
        request_body=RegisterTelegramTriggerSerializer,
        responses={
            200: "OK",
            404: "TelegramTriggerNode not found",
            503: "No webhook tunnel available",
        },
    )
    def post(self, request):
        serializer = RegisterTelegramTriggerSerializer(data=request.data)
        if serializer.is_valid(raise_exception=True):
            telegram_trigger_node_id = serializer.validated_data[
                "telegram_trigger_node_id"
            ]
            telegram_trigger_node = TelegramTriggerNode.objects.filter(
                pk=telegram_trigger_node_id
            ).first()
            if not telegram_trigger_node:
                return Response(
                    {"error": "TelegramTriggerNode not found"},
                    status=status.HTTP_404_NOT_FOUND,
                )

            telegram_trigger_service = TelegramTriggerService()

            telegram_trigger_service.register_telegram_trigger(
                path=telegram_trigger_node.url_path,
                telegram_bot_api_key=telegram_trigger_node.telegram_bot_api_key,
            )

            return Response(status=status.HTTP_200_OK)
